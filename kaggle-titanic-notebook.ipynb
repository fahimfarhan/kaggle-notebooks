{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom skorch import NeuralNetClassifier\nfrom skorch.callbacks import EpochScoring\nfrom torch import nn\nfrom torch import optim\nimport math\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\n\nclass TitanicSurvivalClassifier(nn.Module):\n  def __init__(self, input_size=7, num_classes=1, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n\n    self.sequential = nn.Sequential(\n      nn.Linear(in_features=input_size, out_features=256),\n      nn.ReLU(),\n      nn.Dropout(0.2),\n      nn.Linear(in_features=256, out_features=256),\n      nn.ReLU(),\n      nn.Dropout(0.2),\n      nn.Linear(in_features=256, out_features=256),\n      nn.ReLU(),\n      nn.Dropout(0.2),\n      nn.Linear(in_features=256, out_features=num_classes)\n    )\n\n  def forward(self, x):\n    # print(f\"forward -> { x = }\")\n    return self.sequential(x)\n\n\n# from sklearn import\n# import skorch\ndef cabin_ohe(cabin: str) -> int:\n  try:\n    if cabin == float(\"nan\"):\n      print(\"cabin == nan, returning\")\n      return 0\n    number = int(cabin[1:])\n    character = (1 + ord(cabin[0]) - ord('A'))\n    output = int(character * 1000 + number)\n    return output\n  except Exception as x:\n    mynan = float(\"nan\")\n    print(f\"{ cabin = }, { type(cabin) = }, { mynan = },{ type(mynan) = }, { x = }\")\n    return 0\n\n\ndef cabins_ohe(cabins: pd.Series) -> list:\n  output: list = [cabin_ohe(cabin) for cabin in cabins]\n  return output\n\n\ndef replace_nan_with_avg(input: pd.Series) -> pd.Series:\n  output = input.fillna(input.mean())\n  return output\n\n\ndef generic_ohe(input: pd.Series) -> list:\n  mset = input.unique()\n  dict = {}\n  i = 0\n  for item in mset:\n    dict[item] = i\n\n  mlist: list = [dict[item] for item in input]\n  return mlist\n\n\ndef get_callbacks() -> list:\n  # metric.auc ( uses trapezoidal rule) gave an error: x is neither increasing, nor decreasing. so I had to remove it\n  return [\n    (\"tr_acc\", EpochScoring(\n      metrics.accuracy_score,\n      lower_is_better=False,\n      on_train=True,\n      name=\"train_acc\",\n    )),\n\n    (\"tr_recall\", EpochScoring(\n      metrics.recall_score,\n      lower_is_better=False,\n      on_train=True,\n      name=\"train_recall\",\n    )),\n    # (\"tr_precision\", EpochScoring(\n    #   metrics.precision_score,\n    #   lower_is_better=False,\n    #   on_train=True,\n    #   name=\"train_precision\",\n    # )),\n    (\"tr_roc_auc\", EpochScoring(\n      metrics.roc_auc_score,\n      lower_is_better=False,\n      on_train=False,\n      name=\"tr_auc\"\n    )),\n    (\"tr_f1\", EpochScoring(\n      metrics.f1_score,\n      lower_is_better=False,\n      on_train=False,\n      name=\"tr_f1\"\n    )),\n    # (\"valid_acc1\", EpochScoring(\n    #   metrics.accuracy_score,\n    #   lower_is_better=False,\n    #   on_train=False,\n    #   name=\"valid_acc1\",\n    # )),\n    (\"valid_recall\", EpochScoring(\n      metrics.recall_score,\n      lower_is_better=False,\n      on_train=False,\n      name=\"valid_recall\",\n    )),\n    # (\"valid_precision\", EpochScoring(\n    #   metrics.precision_score,\n    #   lower_is_better=False,\n    #   on_train=False,\n    #   name=\"valid_precision\",\n    # )),\n    (\"valid_roc_auc\", EpochScoring(\n      metrics.roc_auc_score,\n      lower_is_better=False,\n      on_train=False,\n      name=\"valid_auc\"\n    )),\n    (\"valid_f1\", EpochScoring(\n      metrics.f1_score,\n      lower_is_better=False,\n      on_train=False,\n      name=\"valid_f1\"\n    ))\n  ]\n\n\ndef test(net: NeuralNetClassifier):\n  print(\"inside test\")\n  df = pd.read_csv(\"data/test.csv\")\n  headers = [\n    \"PassengerId\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"\n  ]\n\n  # df[\"Cabin\"] = cabins_ohe(df[\"Cabin\"])  # too complex, ignore for now\n  # print(df[\"Cabin\"])\n\n  generic_ohe_needed_headers = [\n    \"Sex\", \"Embarked\"\n  ]\n\n  replace_nan_with_avg_headers = [\n    \"Age\", \"SibSp\", \"Parch\", \"Fare\"\n  ]\n\n  for column in replace_nan_with_avg_headers:\n    df[column] = replace_nan_with_avg(df[column])\n\n  drop_columns = [\n    \"Name\", \"Ticket\", \"Cabin\"\n  ]\n\n  df = df.drop(drop_columns, axis=1)\n  # for column_name in drop_columns:\n\n  for column_name in generic_ohe_needed_headers:\n    df[column_name] = generic_ohe(df[column_name])\n\n  print(df.head())\n\n  # train, val = train_test_split(df, train_size=0.8)\n\n  # X1 = df[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]\n  X1 = df[[\"Sex\", \"Age\"]]\n\n  # print(f\"{len(X1.columns) = }\")\n  # return\n  X = torch.tensor(X1.values)\n\n  passengerIds = df[\"PassengerId\"]\n\n  y = net.predict(X)\n  print(f\"{ y.shape = }\")\n  y = y.squeeze(1)\n  print(f\"{ y.shape = }\")\n\n  result = pd.DataFrame()\n  result[\"PassengerId\"] = passengerIds\n  result[\"Survived\"] = y\n\n  print(f\"{ result.head() = }\")\n  result.to_csv(\"data/results.csv\", index=False)\n  pass\n\n\ndef start():\n  df = pd.read_csv(\"data/train.csv\")\n  headers = [\n    \"PassengerId\", \"Survived\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"\n  ]\n\n  # df[\"Cabin\"] = cabins_ohe(df[\"Cabin\"])  # too complex, ignore for now\n  # print(df[\"Cabin\"])\n\n  generic_ohe_needed_headers = [\n    \"Sex\", \"Embarked\"\n  ]\n\n  replace_nan_with_avg_headers = [\n    \"Age\", \"SibSp\", \"Parch\", \"Fare\"\n  ]\n\n  for column in replace_nan_with_avg_headers:\n    df[column] = replace_nan_with_avg(df[column])\n\n  drop_columns = [\n    \"Name\", \"Ticket\", \"Cabin\"\n  ]\n\n  df = df.drop(drop_columns, axis=1)\n  # for column_name in drop_columns:\n\n  for column_name in generic_ohe_needed_headers:\n    df[column_name] = generic_ohe(df[column_name])\n\n  print(df.head())\n\n  # train, val = train_test_split(df, train_size=0.8)\n\n  # X1 = df[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]\n  X1 = df[[\"Sex\", \"Age\"]]\n\n  # print(f\"{len(X1.columns) = }\")\n  # return\n  X = X1.values\n  y1 = df[\"Survived\"].values * 1.0\n  y = np.expand_dims(y1, axis=1)\n\n  # print(f\"{ type(X) = },\\n{ X = }\")\n  # print(y)\n\n  # return\n\n  # val_x = val[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n  # val_y = val[\"Survived\"]\n\n  titanic_survival_model = TitanicSurvivalClassifier(input_size=len(X1.columns)).double()\n\n  net = NeuralNetClassifier(\n    titanic_survival_model,\n    max_epochs=20,\n    criterion=nn.BCEWithLogitsLoss(),\n    optimizer=torch.optim.Adam,\n    # lr=0.01,\n    lr=0.005,\n    optimizer__weight_decay=1e-5,  # this is the correct way of passing the\n    # optimizer__momentum_decay=0.5,  # weight_decay, momentum_decay etc to NAdam optimizer\n    batch_size=16,\n    # Shuffle training data on each epoch\n    iterator_train__shuffle=True,\n    # train_split=0.8,\n    verbose=True,\n    callbacks=get_callbacks()\n  )\n\n  net.fit(X, y)\n\n  # test the model\n\n  # titanic_survival_model.eval()\n  # predicted = net.predict(X)\n  # print(f\"{ predicted = }\")\n  test(net=net)\n\n  pass\n\n\n# Press the green button in the gutter to run the script.\nif __name__ == \"__main__\":\n  start()\n  # print(cabin_ohe(\"C454\"))\n  pass\n\n# See PyCharm help at https://www.jetbrains.com/help/pycharm/\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}