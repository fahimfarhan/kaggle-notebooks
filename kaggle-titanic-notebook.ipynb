{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install skorch\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom skorch import NeuralNetClassifier\nfrom skorch.callbacks import EpochScoring\nfrom torch import nn\nfrom torch import optim\nimport math\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\n\nclass TitanicSurvivalClassifier(nn.Module):\n  def __init__(self, input_size=7, num_classes=1, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n\n    self.sequential = nn.Sequential(\n      nn.Linear(in_features=input_size, out_features=256),\n      nn.ReLU(),\n      nn.Dropout(0.2),\n      nn.Linear(in_features=256, out_features=256),\n      nn.ReLU(),\n      nn.Dropout(0.2),\n      nn.Linear(in_features=256, out_features=256),\n      nn.ReLU(),\n      nn.Dropout(0.2),\n      nn.Linear(in_features=256, out_features=num_classes)\n    )\n\n  def forward(self, x):\n    # print(f\"forward -> { x = }\")\n    return self.sequential(x)\n\n\n# from sklearn import\n# import skorch\ndef cabin_ohe(cabin: str) -> int:\n  try:\n    if cabin == float(\"nan\"):\n      print(\"cabin == nan, returning\")\n      return 0\n    number = int(cabin[1:])\n    character = (1 + ord(cabin[0]) - ord('A'))\n    output = int(character * 1000 + number)\n    return output\n  except Exception as x:\n    mynan = float(\"nan\")\n    print(f\"{ cabin = }, { type(cabin) = }, { mynan = },{ type(mynan) = }, { x = }\")\n    return 0\n\n\ndef cabins_ohe(cabins: pd.Series) -> list:\n  output: list = [cabin_ohe(cabin) for cabin in cabins]\n  return output\n\n\ndef replace_nan_with_avg(input: pd.Series) -> pd.Series:\n  output = input.fillna(input.mean())\n  return output\n\n\ndef generic_ohe(input: pd.Series) -> list:\n  mset = input.unique()\n  dict = {}\n  i = 0\n  for item in mset:\n    dict[item] = i\n\n  mlist: list = [dict[item] for item in input]\n  return mlist\n\n\ndef get_callbacks() -> list:\n  # metric.auc ( uses trapezoidal rule) gave an error: x is neither increasing, nor decreasing. so I had to remove it\n  return [\n    (\"tr_acc\", EpochScoring(\n      metrics.accuracy_score,\n      lower_is_better=False,\n      on_train=True,\n      name=\"train_acc\",\n    )),\n\n    (\"tr_recall\", EpochScoring(\n      metrics.recall_score,\n      lower_is_better=False,\n      on_train=True,\n      name=\"train_recall\",\n    )),\n    # (\"tr_precision\", EpochScoring(\n    #   metrics.precision_score,\n    #   lower_is_better=False,\n    #   on_train=True,\n    #   name=\"train_precision\",\n    # )),\n    (\"tr_roc_auc\", EpochScoring(\n      metrics.roc_auc_score,\n      lower_is_better=False,\n      on_train=False,\n      name=\"tr_auc\"\n    )),\n    (\"tr_f1\", EpochScoring(\n      metrics.f1_score,\n      lower_is_better=False,\n      on_train=False,\n      name=\"tr_f1\"\n    )),\n    # (\"valid_acc1\", EpochScoring(\n    #   metrics.accuracy_score,\n    #   lower_is_better=False,\n    #   on_train=False,\n    #   name=\"valid_acc1\",\n    # )),\n    (\"valid_recall\", EpochScoring(\n      metrics.recall_score,\n      lower_is_better=False,\n      on_train=False,\n      name=\"valid_recall\",\n    )),\n    # (\"valid_precision\", EpochScoring(\n    #   metrics.precision_score,\n    #   lower_is_better=False,\n    #   on_train=False,\n    #   name=\"valid_precision\",\n    # )),\n    (\"valid_roc_auc\", EpochScoring(\n      metrics.roc_auc_score,\n      lower_is_better=False,\n      on_train=False,\n      name=\"valid_auc\"\n    )),\n    (\"valid_f1\", EpochScoring(\n      metrics.f1_score,\n      lower_is_better=False,\n      on_train=False,\n      name=\"valid_f1\"\n    ))\n  ]\n\n\ndef test(net: NeuralNetClassifier):\n  print(\"inside test\")\n  df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n  headers = [\n    \"PassengerId\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"\n  ]\n\n  # df[\"Cabin\"] = cabins_ohe(df[\"Cabin\"])  # too complex, ignore for now\n  # print(df[\"Cabin\"])\n\n  generic_ohe_needed_headers = [\n    \"Sex\", \"Embarked\"\n  ]\n\n  replace_nan_with_avg_headers = [\n    \"Age\", \"SibSp\", \"Parch\", \"Fare\"\n  ]\n\n  for column in replace_nan_with_avg_headers:\n    df[column] = replace_nan_with_avg(df[column])\n\n  drop_columns = [\n    \"Name\", \"Ticket\", \"Cabin\"\n  ]\n\n  df = df.drop(drop_columns, axis=1)\n  # for column_name in drop_columns:\n\n  for column_name in generic_ohe_needed_headers:\n    df[column_name] = generic_ohe(df[column_name])\n\n  print(df.head())\n\n  # train, val = train_test_split(df, train_size=0.8)\n\n  # X1 = df[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]\n  X1 = df[[\"Sex\", \"Age\"]]\n\n  # print(f\"{len(X1.columns) = }\")\n  # return\n  X = torch.tensor(X1.values)\n\n  passengerIds = df[\"PassengerId\"]\n\n  y = net.predict(X)\n  print(f\"{ y.shape = }\")\n  y = y.squeeze(1)\n  print(f\"{ y.shape = }\")\n\n  result = pd.DataFrame()\n  result[\"PassengerId\"] = passengerIds\n  result[\"Survived\"] = y\n\n  print(f\"{ result.head() = }\")\n  result.to_csv(\"../working/titanic-results.csv\", index=False)\n  pass\n\n\ndef start():\n  df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n  headers = [\n    \"PassengerId\", \"Survived\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"\n  ]\n\n  # df[\"Cabin\"] = cabins_ohe(df[\"Cabin\"])  # too complex, ignore for now\n  # print(df[\"Cabin\"])\n\n  generic_ohe_needed_headers = [\n    \"Sex\", \"Embarked\"\n  ]\n\n  replace_nan_with_avg_headers = [\n    \"Age\", \"SibSp\", \"Parch\", \"Fare\"\n  ]\n\n  for column in replace_nan_with_avg_headers:\n    df[column] = replace_nan_with_avg(df[column])\n\n  drop_columns = [\n    \"Name\", \"Ticket\", \"Cabin\"\n  ]\n\n  df = df.drop(drop_columns, axis=1)\n  # for column_name in drop_columns:\n\n  for column_name in generic_ohe_needed_headers:\n    df[column_name] = generic_ohe(df[column_name])\n\n  print(df.head())\n\n  # train, val = train_test_split(df, train_size=0.8)\n\n  # X1 = df[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]\n  X1 = df[[\"Sex\", \"Age\"]]\n\n  # print(f\"{len(X1.columns) = }\")\n  # return\n  X = X1.values\n  y1 = df[\"Survived\"].values * 1.0\n  y = np.expand_dims(y1, axis=1)\n\n  # print(f\"{ type(X) = },\\n{ X = }\")\n  # print(y)\n\n  # return\n\n  # val_x = val[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n  # val_y = val[\"Survived\"]\n\n  titanic_survival_model = TitanicSurvivalClassifier(input_size=len(X1.columns)).double()\n\n  net = NeuralNetClassifier(\n    titanic_survival_model,\n    max_epochs=20,\n    criterion=nn.BCEWithLogitsLoss(),\n    optimizer=torch.optim.Adam,\n    # lr=0.01,\n    lr=0.005,\n    optimizer__weight_decay=1e-5,  # this is the correct way of passing the\n    # optimizer__momentum_decay=0.5,  # weight_decay, momentum_decay etc to NAdam optimizer\n    batch_size=16,\n    # Shuffle training data on each epoch\n    iterator_train__shuffle=True,\n    # train_split=0.8,\n    verbose=True,\n    callbacks=get_callbacks()\n  )\n\n  net.fit(X, y)\n\n  # test the model\n\n  # titanic_survival_model.eval()\n  # predicted = net.predict(X)\n  # print(f\"{ predicted = }\")\n  test(net=net)\n\n  pass\n\n\n# Press the green button in the gutter to run the script.\nif __name__ == \"__main__\":\n  start()\n  # print(cabin_ohe(\"C454\"))\n  pass\n\n# See PyCharm help at https://www.jetbrains.com/help/pycharm/\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-22T11:06:30.005407Z","iopub.execute_input":"2024-06-22T11:06:30.005829Z","iopub.status.idle":"2024-06-22T11:06:52.516567Z","shell.execute_reply.started":"2024-06-22T11:06:30.005789Z","shell.execute_reply":"2024-06-22T11:06:52.515064Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: skorch in /opt/conda/lib/python3.10/site-packages (1.0.0)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from skorch) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from skorch) (1.2.2)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from skorch) (1.11.4)\nRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from skorch) (0.9.0)\nRequirement already satisfied: tqdm>=4.14.0 in /opt/conda/lib/python3.10/site-packages (from skorch) (4.66.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.0->skorch) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.0->skorch) (3.2.0)\n/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n0            1         0       3    0  22.0      1      0   7.2500         0\n1            2         1       1    0  38.0      1      0  71.2833         0\n2            3         1       3    0  26.0      0      0   7.9250         0\n3            4         1       1    0  35.0      1      0  53.1000         0\n4            5         0       3    0  35.0      0      0   8.0500         0\n  epoch    tr_auc    tr_f1    train_acc    train_loss    train_recall    valid_acc    valid_auc    valid_f1    valid_loss    valid_recall     dur\n-------  --------  -------  -----------  ------------  --------------  -----------  -----------  ----------  ------------  --------------  ------\n      1    \u001b[36m0.5172\u001b[0m   \u001b[32m0.0822\u001b[0m       \u001b[35m0.5801\u001b[0m        \u001b[31m0.9181\u001b[0m          \u001b[94m0.2418\u001b[0m       \u001b[36m0.6257\u001b[0m       \u001b[32m0.5172\u001b[0m      \u001b[35m0.0822\u001b[0m        \u001b[31m0.6631\u001b[0m          \u001b[94m0.0435\u001b[0m  0.3565\n      2    0.5172   0.0822       \u001b[35m0.6166\u001b[0m        \u001b[31m0.6791\u001b[0m          0.0403       0.6257       0.5172      0.0822        0.6702          0.0435  0.2120\n      3    0.5036   0.0789       \u001b[35m0.6250\u001b[0m        \u001b[31m0.6715\u001b[0m          0.0366       0.6089       0.5036      0.0789        0.6709          0.0435  0.2087\n      4    0.5036   0.0789       0.6180        0.6742          0.0549       0.6089       0.5036      0.0789        0.6642          0.0435  0.2031\n      5    0.5172   0.0822       0.6222        0.6773          0.0403       0.6257       0.5172      0.0822        \u001b[31m0.6624\u001b[0m          0.0435  0.2099\n      6    0.5172   0.0822       0.6250        \u001b[31m0.6641\u001b[0m          0.0330       0.6257       0.5172      0.0822        \u001b[31m0.6563\u001b[0m          0.0435  0.2147\n      7    0.5172   0.0822       \u001b[35m0.6292\u001b[0m        0.6682          0.0440       0.6257       0.5172      0.0822        0.6585          0.0435  0.2124\n      8    0.5172   0.0822       0.6278        0.6678          0.0330       0.6257       0.5172      0.0822        0.6573          0.0435  0.2028\n      9    0.5172   0.0822       0.6278        0.6679          0.0330       0.6257       0.5172      0.0822        0.6596          0.0435  0.2008\n     10    0.5172   0.0822       0.6278        0.6641          0.0330       0.6257       0.5172      0.0822        0.6636          0.0435  0.2043\n     11    0.5172   0.0822       0.6250        \u001b[31m0.6636\u001b[0m          0.0256       0.6257       0.5172      0.0822        0.6604          0.0435  0.2153\n     12    0.5172   0.0822       0.6278        \u001b[31m0.6606\u001b[0m          0.0330       0.6257       0.5172      0.0822        0.6646          0.0435  0.2117\n     13    0.5172   0.0822       0.6180        0.6655          0.0549       0.6257       0.5172      0.0822        0.6621          0.0435  0.2397\n     14    0.5172   0.0822       0.6278        0.6639          0.0330       0.6257       0.5172      0.0822        0.6629          0.0435  0.2538\n     15    0.5172   0.0822       0.6264        0.6621          0.0330       0.6257       0.5172      0.0822        0.6592          0.0435  0.2594\n     16    0.5172   0.0822       0.6278        \u001b[31m0.6592\u001b[0m          0.0330       0.6257       0.5172      0.0822        0.6610          0.0435  0.2706\n     17    0.5172   0.0822       0.6264        0.6599          0.0330       0.6257       0.5172      0.0822        0.6615          0.0435  0.2606\n     18    0.5172   0.0822       0.6208        0.6649          0.0586       0.6257       0.5172      0.0822        0.6601          0.0435  0.2240\n     19    0.5036   0.0789       0.6278        \u001b[31m0.6581\u001b[0m          0.0330       0.6089       0.5036      0.0789        0.6646          0.0435  0.2009\n     20    0.5036   0.0789       0.6250        0.6584          0.0330       0.6089       0.5036      0.0789        0.6649          0.0435  0.1957\ninside test\n   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n0          892       3    0  34.5      0      0   7.8292         0\n1          893       3    0  47.0      1      0   7.0000         0\n2          894       2    0  62.0      0      0   9.6875         0\n3          895       3    0  27.0      0      0   8.6625         0\n4          896       3    0  22.0      1      1  12.2875         0\n y.shape = (418, 1)\n y.shape = (418,)\n result.head() =    PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         0\n","output_type":"stream"}]}]}